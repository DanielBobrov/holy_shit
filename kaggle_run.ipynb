{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Reasoning Model - Kaggle Runner\n",
    "\n",
    "Эта рабочая тетрадь демонстрирует работу с моделью итеративных рассуждений, включая обучение, оценку и визуализацию результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка необходимых зависимостей\n",
    "!pip install torch matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Импорт модулей проекта\n",
    "from model import IterativeReasoningModel, ReasoningDataset\n",
    "from train_model import train_model\n",
    "from evaluate_model import evaluate_model\n",
    "from viz_tools import plot_attention_heatmap, plot_representation_trajectory\n",
    "\n",
    "# Определение пути для данных и выходных файлов\n",
    "data_dir = Path('/kaggle/input/reasoning-dataset')\n",
    "output_dir = Path('/kaggle/working')\n",
    "\n",
    "# Создание директорий, если они не существуют\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Проверка доступности GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Используется устройство: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка и подготовка данных\n",
    "\n",
    "Загрузим словарь и наборы данных для обучения, валидации и тестирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пути к файлам данных\n",
    "vocab_path = data_dir / \"vocab.json\"\n",
    "train_path = data_dir / \"train.json\"\n",
    "valid_path = data_dir / \"valid.json\"\n",
    "test_path = data_dir / \"test.json\"\n",
    "\n",
    "# Проверка существования файлов данных\n",
    "if not all(p.exists() for p in [vocab_path, train_path, valid_path, test_path]):\n",
    "    print(\"Файлы данных не найдены, копирование их из репозитория...\")\n",
    "    \n",
    "    # Копирование файлов из репозитория\n",
    "    import shutil\n",
    "    data_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    repo_data_dir = Path('data')\n",
    "    for file_name in ['vocab.json', 'train.json', 'valid.json', 'test.json']:\n",
    "        source = repo_data_dir / file_name\n",
    "        target = data_dir / file_name\n",
    "        if source.exists():\n",
    "            shutil.copy(source, target)\n",
    "            print(f\"Скопирован файл {file_name}\")\n",
    "\n",
    "# Загрузка наборов данных\n",
    "train_dataset = ReasoningDataset(str(train_path), str(vocab_path))\n",
    "val_dataset = ReasoningDataset(str(valid_path), str(vocab_path))\n",
    "test_dataset = ReasoningDataset(str(test_path), str(vocab_path))\n",
    "\n",
    "print(f\"Размер словаря: {len(train_dataset.vocab)}\")\n",
    "print(f\"Примеров для обучения: {len(train_dataset)}\")\n",
    "print(f\"Примеров для валидации: {len(val_dataset)}\")\n",
    "print(f\"Примеров для тестирования: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание и обучение модели\n",
    "\n",
    "Создадим модель итеративного рассуждения и обучим ее на тренировочных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры модели\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "d_ff = 2048\n",
    "num_layers = 8\n",
    "max_iterations = 20\n",
    "dropout = 0.1\n",
    "\n",
    "# Параметры обучения\n",
    "batch_size = 32\n",
    "num_epochs = 500  # Можно увеличить для достижения гроккинга\n",
    "learning_rate = 1e-5\n",
    "weight_decay = 0.01\n",
    "early_stopping_patience = 20\n",
    "\n",
    "# Создание модели\n",
    "model = IterativeReasoningModel(\n",
    "    vocab_size=len(train_dataset.vocab),\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    d_ff=d_ff,\n",
    "    num_layers=num_layers,\n",
    "    max_iterations=max_iterations,\n",
    "    dropout=dropout\n",
    ")\n",
    "\n",
    "# Вывод количества параметров модели\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Количество параметров модели: {num_params:,}\")\n",
    "\n",
    "# Создание директории для контрольных точек\n",
    "checkpoint_dir = output_dir / \"checkpoints\"\n",
    "checkpoint_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Обучение модели\n",
    "model = train_model(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=num_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    device=str(device),\n",
    "    weight_decay=weight_decay,\n",
    "    early_stopping_patience=early_stopping_patience,\n",
    "    checkpoint_dir=str(checkpoint_dir),\n",
    "    use_mixed_precision=True,\n",
    "    use_consistency_loss=True,\n",
    "    consistency_weight=0.1,\n",
    "    gradient_accumulation_steps=1\n",
    ")\n",
    "\n",
    "# Сохранение обученной модели\n",
    "model_path = output_dir / \"model.pt\"\n",
    "torch.save(model.state_dict(), str(model_path))\n",
    "print(f\"Модель сохранена в {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка модели\n",
    "\n",
    "Оценим производительность модели на тестовом наборе данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка модели\n",
    "metrics = evaluate_model(\n",
    "    model=model,\n",
    "    test_dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    device=str(device)\n",
    ")\n",
    "\n",
    "# Сохранение метрик в файл\n",
    "metrics_path = output_dir / \"metrics.json\"\n",
    "with open(metrics_path, 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "# Визуализация метрик\n",
    "type_names = list(metrics.keys())\n",
    "accuracies = [metrics[t]['correct'] / metrics[t]['total'] for t in type_names]\n",
    "counts = [metrics[t]['total'] for t in type_names]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(type_names, accuracies, color='skyblue')\n",
    "plt.title('Точность по типам данных')\n",
    "plt.xlabel('Тип')\n",
    "plt.ylabel('Точность')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Добавление текста с точностью над каждым столбцом\n",
    "for bar, acc, count in zip(bars, accuracies, counts):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "             f\"{acc:.2f}\\n({count})\", ha='center')\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / \"accuracy_by_type.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация внимания и процесса рассуждения\n",
    "\n",
    "Визуализируем механизм внимания и процесс итеративного рассуждения для нескольких примеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание словаря, отображающего ID токена в читаемое представление\n",
    "token_ids_to_words = {idx: token for idx, token in enumerate(train_dataset.vocab)}\n",
    "\n",
    "# Выбор нескольких примеров для визуализации\n",
    "viz_examples = [test_dataset[i] for i in range(3)]\n",
    "\n",
    "for i, example in enumerate(viz_examples):\n",
    "    print(f\"\\nПример {i+1}:\")\n",
    "    \n",
    "    # Преобразование входных токенов в читаемый текст\n",
    "    input_text = ' '.join([token_ids_to_words.get(t.item(), f\"<{t.item()}>\") for t in example['input_ids']])\n",
    "    target_text = ' '.join([token_ids_to_words.get(t.item(), f\"<{t.item()}>\") for t in example['target_ids']])\n",
    "    \n",
    "    print(f\"Входной текст: {input_text}\")\n",
    "    print(f\"Целевой текст: {target_text}\")\n",
    "    print(f\"Тип: {example['type']}\")\n",
    "    \n",
    "    # Подготовка входных данных\n",
    "    input_ids = example['input_ids'].unsqueeze(0).to(device)\n",
    "    \n",
    "    # Визуализация внимания\n",
    "    attention_path = output_dir / f\"attention_example_{i+1}.png\"\n",
    "    model.visualize_attention(\n",
    "        tokens=input_ids,\n",
    "        token_ids_to_words=token_ids_to_words,\n",
    "        mask_token_id=test_dataset.mask_token_id,\n",
    "        save_path=str(attention_path)\n",
    "    )\n",
    "    \n",
    "    # Визуализация процесса рассуждения\n",
    "    reasoning_path = output_dir / f\"reasoning_example_{i+1}.png\"\n",
    "    model.visualize_iterative_reasoning(\n",
    "        tokens=input_ids,\n",
    "        mask_token_id=test_dataset.mask_token_id,\n",
    "        token_ids_to_words=token_ids_to_words,\n",
    "        save_path=str(reasoning_path)\n",
    "    )\n",
    "    \n",
    "    # Показ результатов\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(plt.imread(attention_path))\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Карта внимания\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(plt.imread(reasoning_path))\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Траектория рассуждения\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / f\"visualization_example_{i+1}.png\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование влияния количества итераций на точность\n",
    "\n",
    "Проверим, как изменяется точность модели при разном количестве итераций рассуждения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список количеств итераций для тестирования\n",
    "iterations_list = [1, 2, 5, 10, 15, 20, 25, 30]\n",
    "\n",
    "# Создаем подмножество тестовых данных для быстрого тестирования\n",
    "subset_indices = torch.randperm(len(test_dataset))[:100]\n",
    "subset_dataset = torch.utils.data.Subset(test_dataset, subset_indices)\n",
    "\n",
    "# Создаем даталоадер\n",
    "subset_loader = torch.utils.data.DataLoader(\n",
    "    subset_dataset, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "# Список для хранения результатов\n",
    "accuracies = []\n",
    "\n",
    "# Тестирование с разным числом итераций\n",
    "model.eval()\n",
    "for num_iterations in iterations_list:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(subset_loader):\n",
    "            input_ids = batch[0]['input_ids'].to(device)\n",
    "            target_ids = batch[0]['target_ids'].to(device)\n",
    "            \n",
    "            # Генерация предсказаний с заданным числом итераций\n",
    "            predictions = model.generate(\n",
    "                input_ids,\n",
    "                mask_token_id=test_dataset.mask_token_id,\n",
    "                num_iterations=num_iterations\n",
    "            )\n",
    "            \n",
    "            # Подсчет точности\n",
    "            matches = (predictions == target_ids).all(dim=1)\n",
    "            correct += matches.sum().item()\n",
    "            total += len(matches)\n",
    "    \n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Количество итераций: {num_iterations}, Точность: {accuracy:.4f} ({correct}/{total})\")\n",
    "\n",
    "# Визуализация результатов\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(iterations_list, accuracies, marker='o', linestyle='-', linewidth=2, markersize=8)\n",
    "plt.title('Влияние количества итераций на точность')\n",
    "plt.xlabel('Количество итераций')\n",
    "plt.ylabel('Точность')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Добавление текста с точностью\n",
    "for i, (x, y) in enumerate(zip(iterations_list, accuracies)):\n",
    "    plt.text(x, y, f\"{y:.4f}\", ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / \"iterations_vs_accuracy.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заключение\n",
    "\n",
    "В этом ноутбуке мы обучили, оценили и визуализировали работу модели итеративного рассуждения. Результаты показывают эффективность подхода итеративного рассуждения, особенно для задач, требующих логического анализа и интеграции разрозненной информации."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
